# -*- coding: utf-8 -*-
"""danbooru_hbr_dataset_sample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CNMfZj85huZryarG4Cggpz5_1UDRiD80
"""

# ===== ì„¤ì • =====
character_tag = "shirakawa_yuina"   # ì´ë²ˆ í…ŒìŠ¤íŠ¸ ìºë¦­í„°
copyright_tag = "heaven_burns_red"  # í•„ìš”í•˜ë©´ ìœ ì§€, ì›ì¹˜ ì•Šìœ¼ë©´ ""ë¡œ

sleep_sec = 1.0
retries = 10

# ê²°ê³¼ ì €ì¥ ë£¨íŠ¸(Colab ë¡œì»¬)
dataset_root = f"/content/danbooru_{character_tag}"

# --- í•„í„° ì„¤ì • (general) ---
# - í‘œí˜„ì‹ì€ and/or/not, ê´„í˜¸ ì§€ì›
# - ì˜ˆ: "(1girl and solo) or 2girls"
general_include_expr = "(1girl and solo) or 2girls"

# include_exprì´ ë¹„ì–´ ìˆì„ ë•Œë§Œ ì‚¬ìš© (OR-of-AND)
# ì˜ˆ: [["1girl", "solo"], ["2girls"]]
general_include_groups = []

# í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ì œì™¸
general_exclude_tags = [
    "3girls",
    "4girls",
    "5girls",
    "6+girls",
    "4koma",
    "comic",
]

# --- í•„í„° ì„¤ì • (copyright) ---
# ë¹„ì›Œë‘ë©´ í•„í„° ì•ˆ í•¨
copyright_required = "heaven_burns_red"

# Trueë©´ í•´ë‹¹ íƒœê·¸ë§Œ ë‹¨ë…ìœ¼ë¡œ ìˆì„ ë•Œë§Œ í†µê³¼
copyright_solo_only = True

# Google Drive ì‚¬ìš© ì•ˆ í•¨ (/contentì— ì €ì¥)

!pip -q install -U gallery-dl
!gallery-dl --version

!gallery-dl --help | grep -i -E "concurrent|jobs|thread|rate|sleep"

import os

tags = [character_tag]
if copyright_tag:
    tags.append(copyright_tag)

tag_query = "+".join(tags)
url = f"https://danbooru.donmai.us/posts?tags={tag_query}"

print("URL:", url)

import os

data_dir = os.path.join(dataset_root, "danbooru")
os.makedirs(data_dir, exist_ok=True)
print("data_dir:", data_dir)

cmd = f'''gallery-dl \
  --directory "{data_dir}" \
  --filename "{{id}}_{{md5}}.{{extension}}" \
  --write-metadata \
  --retries {retries} \
  --sleep {sleep_sec} \
  "{url}"
'''
print(cmd)
!{cmd}

import os, glob, json
from pathlib import Path

# ì´ë¯¸ì§€ ì „ìš© í™•ì¥ì
IMAGE_EXTS = (".jpg", ".jpeg", ".png", ".webp", ".gif")
img_exts = IMAGE_EXTS

# --- í•„í„° ì„¤ì • ì •ê·œí™” ---
GENERAL_INCLUDE_EXPR = (general_include_expr or "").strip()
GENERAL_EXCLUDE_TAGS = {str(t).lower() for t in (general_exclude_tags or []) if t}

GENERAL_INCLUDE_GROUPS = []
for group in (general_include_groups or []):
    if group:
        GENERAL_INCLUDE_GROUPS.append({str(t).lower() for t in group if t})

COPYRIGHT_REQUIRED = (copyright_required or "").strip().lower()
COPYRIGHT_SOLO_ONLY = bool(copyright_solo_only)


def split_tags(s: str):
    return {t.lower() for t in (s or "").split()}


def is_image_path(path: str) -> bool:
    return Path(path).suffix.lower() in IMAGE_EXTS


def key_from_json(jp: str) -> str:
    return jp[:-5]  # ".json" ì œê±°


def key_from_caption(cp: str) -> str:
    return cp[:-len(".caption.txt")]


def is_image_json(jp: str) -> bool:
    return is_image_path(key_from_json(jp))


def tokenize_expr(expr: str):
    tokens = []
    i = 0
    while i < len(expr):
        ch = expr[i]
        if ch.isspace():
            i += 1
            continue
        if ch in "()":
            tokens.append(ch)
            i += 1
            continue
        j = i
        while j < len(expr) and (not expr[j].isspace()) and (expr[j] not in "()"):
            j += 1
        tokens.append(expr[i:j])
        i = j
    return tokens


def to_rpn(tokens):
    prec = {"or": 1, "and": 2, "not": 3}
    out = []
    stack = []
    for tok in tokens:
        t = tok.lower()
        if t in prec:
            while stack and stack[-1] != "(" and prec.get(stack[-1], 0) >= prec[t]:
                out.append(stack.pop())
            stack.append(t)
        elif tok == "(":
            stack.append(tok)
        elif tok == ")":
            while stack and stack[-1] != "(":
                out.append(stack.pop())
            if not stack:
                raise ValueError("ê´„í˜¸ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            stack.pop()
        else:
            out.append(tok)
    while stack:
        if stack[-1] == "(":
            raise ValueError("ê´„í˜¸ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        out.append(stack.pop())
    return out


def compile_expr(expr: str):
    tokens = tokenize_expr(expr)
    if not tokens:
        return []
    return to_rpn(tokens)


def eval_rpn(rpn, tags: set):
    stack = []
    for tok in rpn:
        t = tok.lower()
        if t == "and":
            if len(stack) < 2:
                raise ValueError("AND ì—°ì‚° í•­ëª©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            b = stack.pop()
            a = stack.pop()
            stack.append(a and b)
        elif t == "or":
            if len(stack) < 2:
                raise ValueError("OR ì—°ì‚° í•­ëª©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            b = stack.pop()
            a = stack.pop()
            stack.append(a or b)
        elif t == "not":
            if not stack:
                raise ValueError("NOT ì—°ì‚° í•­ëª©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            a = stack.pop()
            stack.append(not a)
        else:
            stack.append(t in tags)
    if len(stack) != 1:
        raise ValueError("íƒœê·¸ í‘œí˜„ì‹ì„ í‰ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return stack[0]


GENERAL_INCLUDE_RPN = compile_expr(GENERAL_INCLUDE_EXPR) if GENERAL_INCLUDE_EXPR else []


def match_general(tags: set) -> bool:
    if GENERAL_EXCLUDE_TAGS & tags:
        return False
    if GENERAL_INCLUDE_RPN:
        return eval_rpn(GENERAL_INCLUDE_RPN, tags)
    if GENERAL_INCLUDE_GROUPS:
        for group in GENERAL_INCLUDE_GROUPS:
            if group.issubset(tags):
                return True
        return False
    return True


def match_copyright(meta: dict) -> bool:
    if not COPYRIGHT_REQUIRED:
        return True
    tags = split_tags(meta.get("tag_string_copyright"))
    if COPYRIGHT_SOLO_ONLY:
        return tags == {COPYRIGHT_REQUIRED}
    return COPYRIGHT_REQUIRED in tags


def is_allowed(meta: dict) -> bool:
    general_tags = split_tags(meta.get("tag_string_general"))
    return match_general(general_tags) and match_copyright(meta)

json_files = glob.glob(os.path.join(data_dir, "*.json"))
img_json_files = [jp for jp in json_files if is_image_json(jp)]
print("json files (image):", len(img_json_files))

skipped_non_image = len(json_files) - len(img_json_files)
if skipped_non_image:
    print("skipped non-image json:", skipped_non_image)


def make_caption(meta):
    parts = []
    for key in ["tag_string_artist", "tag_string_copyright", "tag_string_character", "tag_string_general"]:
        v = (meta.get(key) or "").strip()
        if v:
            parts.append(v)
    return " ".join(parts).strip()


empty = 0
kept = 0
skipped_rule = 0

for jp in img_json_files:
    with open(jp, "r", encoding="utf-8") as f:
        meta = json.load(f)

    if not is_allowed(meta):
        skipped_rule += 1
        continue

    caption = make_caption(meta)

    img_path = key_from_json(jp)
    cap_path = img_path + ".caption.txt"

    with open(cap_path, "w", encoding="utf-8") as f:
        f.write(caption + "\n")

    if not caption:
        empty += 1

    kept += 1

print("filtered by rules:", skipped_rule)
print("captions made:", kept)
print("empty captions:", empty)

# --- 1) JSON í•„í„°ë§ ---
json_files = glob.glob(os.path.join(data_dir, "*.json"))
json_files = [jp for jp in json_files if is_image_json(jp)]

allowed_json_files = []
skipped_rule = 0

for jp in json_files:
    with open(jp, "r", encoding="utf-8") as f:
        meta = json.load(f)

    if not is_allowed(meta):
        skipped_rule += 1
        continue

    allowed_json_files.append(jp)

# --- 2) ê¸°ëŒ€ ê²½ë¡œ ìƒì„± ---
img_paths = [key_from_json(jp) for jp in allowed_json_files]
cap_paths = [p + ".caption.txt" for p in img_paths]

missing_img = sorted([p for p in img_paths if not os.path.exists(p)])
missing_cap = sorted([p for p in cap_paths if not os.path.exists(p)])

print("json (image):", len(json_files))
print("filtered by rules:", skipped_rule)
print("images (expected):", len(img_paths))
print("caps (expected):", len(cap_paths))
print()
print("missing image:", len(missing_img))
print("missing caption:", len(missing_cap))
print("\nSample missing image:", missing_img[:3])
print("Sample missing cap:", missing_cap[:3])

# --- 3) ì¸ë±ìŠ¤(jsonl) ìƒì„± ---
out_path = os.path.join(dataset_root, "dataset_index_fixed.jsonl")

missing_img_idx = 0
missing_cap_idx = 0

with open(out_path, "w", encoding="utf-8") as out:
    for jp in allowed_json_files:
        with open(jp, "r", encoding="utf-8") as f:
            meta = json.load(f)

        img_path = key_from_json(jp)
        cap_path = img_path + ".caption.txt"

        if not os.path.exists(img_path):
            missing_img_idx += 1
            continue
        if not os.path.exists(cap_path):
            missing_cap_idx += 1
            continue

        rec = {
            "post_id": meta.get("id"),
            "image_path": img_path,
            "json_path": jp,
            "caption_path": cap_path,

            "artist": (meta.get("tag_string_artist") or "").split(),
            "copyright": (meta.get("tag_string_copyright") or "").split(),
            "character": (meta.get("tag_string_character") or "").split(),
            "general": (meta.get("tag_string_general") or "").split(),
        }
        out.write(json.dumps(rec, ensure_ascii=False) + "\n")

print("\nrecords:", len(allowed_json_files))
print("missing image:", missing_img_idx)
print("missing caption:", missing_cap_idx)
print("saved:", out_path)

import random, json, os, glob
from IPython.display import display, Image, Markdown

img_files = []
for e in img_exts:
    img_files += glob.glob(os.path.join(data_dir, f"*{e}"))

samples = random.sample(img_files, k=min(2, len(img_files)))


def find_json(img_path):
    return img_path + ".json"


def show_one(img_path):
    jp = find_json(img_path)
    with open(jp, "r", encoding="utf-8") as f:
        meta = json.load(f)

    post_id = meta.get("id")
    link = f"https://danbooru.donmai.us/posts/{post_id}"

    cap_path = img_path + ".caption.txt"
    caption_text = open(cap_path, encoding="utf-8").read().strip() if os.path.exists(cap_path) else ""

    display(Markdown("### Sample"))
    display(Markdown(f"- **image**: `{img_path}`"))
    display(Markdown(f"- **json**: `{jp}`"))
    display(Markdown(f"- **caption**: `{cap_path}`"))
    display(Markdown(f"- **danbooru id**: `{post_id}`"))
    display(Markdown(f"- **danbooru link**: {link}"))
    display(Image(filename=img_path))

    display(Markdown("**Tags (by category)**"))
    display(Markdown(f"- artist: `{meta.get('tag_string_artist','')}`"))
    display(Markdown(f"- copyright: `{meta.get('tag_string_copyright','')}`"))
    display(Markdown(f"- character: `{meta.get('tag_string_character','')}`"))
    g = meta.get("tag_string_general","")
    display(Markdown(f"- general (head): `{g[:200]}{'...' if len(g)>200 else ''}`"))

    display(Markdown("**Caption file content (head)**"))
    display(Markdown(f"`{caption_text[:300]}{'...' if len(caption_text)>300 else ''}`"))


for p in samples:
    show_one(p)

!pip -q install pillow

!unzip -o viewer_colab.zip -d /content/viewer
!ls /content/viewer

import subprocess, socket, time

PORT = 8188
ROOT = data_dir  # ipynbì—ì„œ ë§Œë“  í´ë”

viewer_proc = subprocess.Popen(
    ["python", "/content/viewer/server.py", "--root", ROOT, "--port", str(PORT)]
)

def wait_port(port):
    while True:
        time.sleep(0.5)
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            if sock.connect_ex(("127.0.0.1", port)) == 0:
                break

wait_port(PORT)
print(f"âœ… Viewer ì„œë²„ ì¤€ë¹„ ì™„ë£Œ: http://127.0.0.1:{PORT} (ì½œë© ë‚´ë¶€)")

# cloudflared ì„¤ì¹˜ (Colab/Linux)
if not os.path.exists("/root/cloudflared-linux-amd64.deb"):
    !wget -q -P /root/ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
    !dpkg -i /root/cloudflared-linux-amd64.deb

!cloudflared tunnel --url http://127.0.0.1:8188

# ---------------------------------------------------------
# ë·°ì–´ ì‹¤í–‰ (Colab ì „ìš©)
# ---------------------------------------------------------
import os, time, socket, subprocess, threading

PORT = 8188
ROOT = data_dir  # ipynbì—ì„œ ë§Œë“  ë°ì´í„° í´ë” ì‚¬ìš© (ì˜ˆ: /content/.../danbooru)

# cloudflared ì„¤ì¹˜
if not os.path.exists("/root/cloudflared-linux-amd64.deb"):
    !wget -q -P /root/ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
    !dpkg -i /root/cloudflared-linux-amd64.deb

# ë·°ì–´ ì„œë²„ ì‹¤í–‰
# viewer í´ë”ê°€ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•¨
viewer_proc = subprocess.Popen(
    ["python", "viewer/server.py", "--root", ROOT, "--port", str(PORT)]
)

def wait_port(port):
    while True:
        time.sleep(0.5)
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            if sock.connect_ex(("127.0.0.1", port)) == 0:
                break

def tunnel_thread(port):
    wait_port(port)
    print("\nâœ… ì ‘ì† ì¤€ë¹„ ì™„ë£Œ! ì•„ë˜ ë§í¬ë¥¼ í´ë¦­í•˜ì„¸ìš”:\n")
    p = subprocess.Popen(
        ["cloudflared", "tunnel", "--url", f"http://127.0.0.1:{port}"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )
    for line in p.stderr:
        l = line.decode()
        if "trycloudflare.com" in l:
            print("ğŸ”— LINK:", l[l.find("http"):].strip())

threading.Thread(target=tunnel_thread, daemon=True, args=(PORT,)).start()
print(f"ğŸš€ Viewer ì‹œì‘! (ë¡œì»¬: http://127.0.0.1:{PORT})")